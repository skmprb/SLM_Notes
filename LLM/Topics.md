* Foundations of Natural Language Processing

  * Text normalization
  * Tokenization

    * Word tokenization
    * Subword tokenization
    * Character tokenization
    * Byte-level tokenization
  * Vocabulary construction
  * Vocabulary size
  * Encoding schemes

    * One-hot encoding
    * Integer encoding
  * Decoding schemes

* Linguistic Representations

  * N-grams
  * Bag-of-Words
  * TF-IDF
  * Word embeddings

    * Word2Vec
    * GloVe
    * FastText

* Neural Network Fundamentals

  * Perceptrons
  * Feedforward neural networks
  * Activation functions
  * Loss functions
  * Backpropagation
  * Gradient descent
  * Optimization algorithms

* Sequence Modeling

  * Recurrent Neural Networks
  * Vanishing and exploding gradients
  * Long Short-Term Memory (LSTM)
  * Gated Recurrent Units (GRU)
  * Sequence-to-sequence models
  * Encoder–decoder architecture

* Attention Mechanisms

  * Attention concept
  * Additive attention
  * Multiplicative attention
  * Self-attention
  * Cross-attention

* Transformer Architecture

  * Transformer overview
  * Input embeddings
  * Positional encoding
  * Multi-head attention
  * Feedforward networks
  * Residual connections
  * Layer normalization
  * Encoder stack
  * Decoder stack

* Language Modeling

  * Statistical language models
  * Neural language models
  * Autoregressive modeling
  * Masked language modeling
  * Causal language modeling

* Training Large Language Models

  * Pretraining objectives
  * Next-token prediction
  * Training data collection
  * Data preprocessing
  * Batch processing
  * Token batching and padding
  * Mixed-precision training
  * Distributed training
  * Model parallelism
  * Data parallelism

* Inference and Decoding Strategies

  * Greedy decoding
  * Beam search
  * Top-k sampling
  * Top-p (nucleus) sampling
  * Temperature scaling
  * Repetition penalties

* Scaling Laws and Model Size

  * Parameter count
  * Model depth and width
  * Context window
  * Compute scaling
  * Data scaling

* Model Architectures and Variants

  * Decoder-only models
  * Encoder-only models
  * Encoder–decoder models
  * Dense models
  * Sparse models
  * Mixture of Experts

* Fine-Tuning Techniques

  * Supervised fine-tuning
  * Instruction tuning
  * Parameter-efficient fine-tuning

    * LoRA
    * Adapters
    * Prefix tuning
  * Continual learning

* Alignment and Safety

  * Human feedback
  * Reinforcement Learning from Human Feedback (RLHF)
  * Reward modeling
  * Safety alignment
  * Bias and fairness

* Evaluation of Language Models

  * Perplexity
  * Accuracy-based metrics
  * BLEU
  * ROUGE
  * Human evaluation
  * Benchmark datasets

* Optimization and Efficiency

  * Quantization
  * Pruning
  * Knowledge distillation
  * Caching
  * KV cache optimization

* Context and Memory Handling

  * Context length limitations
  * Sliding window attention
  * Long-context models
  * Retrieval-augmented generation

* Retrieval-Augmented and Hybrid Systems

  * Embedding models
  * Vector databases
  * Similarity search
  * Retrieval pipelines
  * RAG architectures

* Multimodal Language Models

  * Text–image models
  * Text–audio models
  * Vision-language transformers
  * Multimodal fusion

* Deployment and Serving

  * Model serialization
  * Inference optimization
  * Batch inference
  * Streaming inference
  * Latency and throughput
  * Model monitoring

* Ethics, Privacy, and Governance

  * Data privacy
  * Model misuse
  * Intellectual property
  * Regulatory considerations

* Applications of Large Language Models

  * Text generation
  * Question answering
  * Summarization
  * Translation
  * Code generation
  * Conversational agents

* Future Directions in Large Language Models

  * Long-term memory
  * Tool-augmented models
  * Autonomous agents
  * Self-improving systems

* Probabilistic Foundations

  * Probability distributions
  * Maximum likelihood estimation
  * Cross-entropy loss
  * KL divergence

* Tokenizer Algorithms

  * Byte Pair Encoding (BPE)
  * Unigram Language Model
  * SentencePiece
  * WordPiece

* Numerical Stability and Training Dynamics

  * Weight initialization
  * Gradient clipping
  * Learning rate schedules
  * Warmup strategies

* Positional Representation Variants

  * Learned positional embeddings
  * Relative positional encoding
  * Rotary positional embeddings (RoPE)
  * ALiBi

* Attention Optimizations

  * FlashAttention
  * Sparse attention
  * Linear attention
  * Sliding window attention

* Long-Context Architectures

  * Memory-augmented transformers
  * Recurrence in transformers
  * Hierarchical attention

* Pretraining Data Engineering

  * Data deduplication
  * Data filtering
  * Data contamination
  * Dataset balancing

* Prompting and Inference Control

  * Prompt engineering
  * In-context learning
  * Few-shot prompting
  * Chain-of-thought
  * Self-consistency
  * Tool calling

* Agentic LLM Systems

  * Planning
  * Reflection
  * ReAct pattern
  * Multi-agent systems

* Hallucination and Reliability

  * Hallucination types
  * Faithfulness
  * Grounding

* Security and Robustness

  * Prompt injection
  * Jailbreak attacks
  * Model extraction
  * Adversarial prompting

* LLM System Design

  * End-to-end LLM pipelines
  * Orchestration frameworks
  * Caching strategies
  * Cost optimization

* Benchmarking and Evaluation at Scale

  * Red-teaming
  * Evals harnesses
  * Continuous evaluation

* Open-Source and Model Ecosystem

  * Model checkpoints
  * Model licensing
  * Open vs closed models
