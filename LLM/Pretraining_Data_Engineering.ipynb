{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Data Engineering for LLMs\n",
    "\n",
    "## Overview\n",
    "\n",
    "Data engineering for LLM pretraining involves sophisticated techniques to ensure high-quality, diverse, and uncontaminated training datasets. This notebook covers:\n",
    "\n",
    "- **Data Deduplication**: Exact and near-duplicate detection using MinHash and LSH\n",
    "- **Data Filtering**: Quality-based and content-based filtering strategies\n",
    "- **Contamination Detection**: Test set and benchmark contamination analysis\n",
    "- **Dataset Balancing**: Domain, quality, and temporal balancing techniques\n",
    "\n",
    "Let's implement practical data engineering pipelines for LLM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hashlib\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Set, Tuple, Any\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Deduplication System\n",
    "\n",
    "Let's implement a comprehensive deduplication system using exact matching, MinHash, and LSH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinHashDeduplicator:\n",
    "    \"\"\"MinHash-based deduplication for near-duplicate detection\"\"\"\n",
    "    \n",
    "    def __init__(self, num_hashes=128, shingle_size=3):\n",
    "        self.num_hashes = num_hashes\n",
    "        self.shingle_size = shingle_size\n",
    "        self.hash_functions = self._generate_hash_functions()\n",
    "        self.signatures = {}\n",
    "        self.lsh_buckets = defaultdict(list)\n",
    "        self.bands = 16  # Number of LSH bands\n",
    "        self.rows_per_band = num_hashes // self.bands\n",
    "    \n",
    "    def _generate_hash_functions(self):\n",
    "        \"\"\"Generate hash functions for MinHash\"\"\"\n",
    "        # Use different seeds for different hash functions\n",
    "        hash_functions = []\n",
    "        for i in range(self.num_hashes):\n",
    "            # Create hash function with different parameters\n",
    "            a = random.randint(1, 2**32 - 1)\n",
    "            b = random.randint(0, 2**32 - 1)\n",
    "            hash_functions.append((a, b))\n",
    "        return hash_functions\n",
    "    \n",
    "    def _create_shingles(self, text):\n",
    "        \"\"\"Create character-level shingles from text\"\"\"\n",
    "        # Normalize text\n",
    "        text = re.sub(r'\\s+', ' ', text.lower().strip())\n",
    "        \n",
    "        # Create shingles\n",
    "        shingles = set()\n",
    "        for i in range(len(text) - self.shingle_size + 1):\n",
    "            shingle = text[i:i + self.shingle_size]\n",
    "            shingles.add(shingle)\n",
    "        \n",
    "        return shingles\n",
    "    \n",
    "    def _hash_shingle(self, shingle, a, b):\n",
    "        \"\"\"Hash a shingle using linear hash function\"\"\"\n",
    "        # Convert shingle to integer\n",
    "        shingle_int = hash(shingle) % (2**32)\n",
    "        return (a * shingle_int + b) % (2**32)\n",
    "    \n",
    "    def compute_minhash_signature(self, text, doc_id):\n",
    "        \"\"\"Compute MinHash signature for a document\"\"\"\n",
    "        shingles = self._create_shingles(text)\n",
    "        \n",
    "        if not shingles:\n",
    "            return None\n",
    "        \n",
    "        signature = []\n",
    "        \n",
    "        for a, b in self.hash_functions:\n",
    "            min_hash = float('inf')\n",
    "            \n",
    "            for shingle in shingles:\n",
    "                hash_val = self._hash_shingle(shingle, a, b)\n",
    "                min_hash = min(min_hash, hash_val)\n",
    "            \n",
    "            signature.append(min_hash)\n",
    "        \n",
    "        self.signatures[doc_id] = signature\n",
    "        return signature\n",
    "    \n",
    "    def estimate_jaccard_similarity(self, sig1, sig2):\n",
    "        \"\"\"Estimate Jaccard similarity from MinHash signatures\"\"\"\n",
    "        if len(sig1) != len(sig2):\n",
    "            return 0.0\n",
    "        \n",
    "        matches = sum(1 for h1, h2 in zip(sig1, sig2) if h1 == h2)\n",
    "        return matches / len(sig1)\n",
    "    \n",
    "    def add_to_lsh(self, doc_id, signature):\n",
    "        \"\"\"Add document to LSH buckets for efficient similarity search\"\"\"\n",
    "        for band in range(self.bands):\n",
    "            start_idx = band * self.rows_per_band\n",
    "            end_idx = start_idx + self.rows_per_band\n",
    "            band_signature = tuple(signature[start_idx:end_idx])\n",
    "            \n",
    "            # Hash the band signature to create bucket key\n",
    "            bucket_key = hash(band_signature)\n",
    "            self.lsh_buckets[bucket_key].append(doc_id)\n",
    "    \n",
    "    def find_similar_documents(self, doc_id, similarity_threshold=0.8):\n",
    "        \"\"\"Find documents similar to the given document using LSH\"\"\"\n",
    "        if doc_id not in self.signatures:\n",
    "            return []\n",
    "        \n",
    "        signature = self.signatures[doc_id]\n",
    "        candidate_docs = set()\n",
    "        \n",
    "        # Find candidates from LSH buckets\n",
    "        for band in range(self.bands):\n",
    "            start_idx = band * self.rows_per_band\n",
    "            end_idx = start_idx + self.rows_per_band\n",
    "            band_signature = tuple(signature[start_idx:end_idx])\n",
    "            bucket_key = hash(band_signature)\n",
    "            \n",
    "            if bucket_key in self.lsh_buckets:\n",
    "                candidate_docs.update(self.lsh_buckets[bucket_key])\n",
    "        \n",
    "        # Remove self\n",
    "        candidate_docs.discard(doc_id)\n",
    "        \n",
    "        # Verify similarity for candidates\n",
    "        similar_docs = []\n",
    "        for candidate_id in candidate_docs:\n",
    "            if candidate_id in self.signatures:\n",
    "                similarity = self.estimate_jaccard_similarity(\n",
    "                    signature, self.signatures[candidate_id]\n",
    "                )\n",
    "                if similarity >= similarity_threshold:\n",
    "                    similar_docs.append((candidate_id, similarity))\n",
    "        \n",
    "        # Sort by similarity\n",
    "        similar_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return similar_docs\n",
    "\n",
    "class DataDeduplicationPipeline:\n",
    "    \"\"\"Comprehensive data deduplication pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.exact_hashes = set()\n",
    "        self.minhash_deduplicator = MinHashDeduplicator()\n",
    "        self.deduplication_stats = {\n",
    "            'total_documents': 0,\n",
    "            'exact_duplicates': 0,\n",
    "            'near_duplicates': 0,\n",
    "            'unique_documents': 0\n",
    "        }\n",
    "        self.processed_documents = {}\n",
    "    \n",
    "    def process_document(self, doc_id, text, similarity_threshold=0.8):\n",
    "        \"\"\"Process a single document through deduplication pipeline\"\"\"\n",
    "        self.deduplication_stats['total_documents'] += 1\n",
    "        \n",
    "        # Step 1: Exact deduplication\n",
    "        exact_hash = hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        if exact_hash in self.exact_hashes:\n",
    "            self.deduplication_stats['exact_duplicates'] += 1\n",
    "            return {\n",
    "                'doc_id': doc_id,\n",
    "                'is_duplicate': True,\n",
    "                'duplicate_type': 'exact',\n",
    "                'similarity': 1.0,\n",
    "                'action': 'remove'\n",
    "            }\n",
    "        \n",
    "        self.exact_hashes.add(exact_hash)\n",
    "        \n",
    "        # Step 2: Near-duplicate detection using MinHash\n",
    "        signature = self.minhash_deduplicator.compute_minhash_signature(text, doc_id)\n",
    "        \n",
    "        if signature is None:\n",
    "            return {\n",
    "                'doc_id': doc_id,\n",
    "                'is_duplicate': False,\n",
    "                'duplicate_type': 'none',\n",
    "                'similarity': 0.0,\n",
    "                'action': 'keep',\n",
    "                'note': 'empty_or_too_short'\n",
    "            }\n",
    "        \n",
    "        # Add to LSH for future similarity searches\n",
    "        self.minhash_deduplicator.add_to_lsh(doc_id, signature)\n",
    "        \n",
    "        # Find similar documents\n",
    "        similar_docs = self.minhash_deduplicator.find_similar_documents(\n",
    "            doc_id, similarity_threshold\n",
    "        )\n",
    "        \n",
    "        if similar_docs:\n",
    "            self.deduplication_stats['near_duplicates'] += 1\n",
    "            best_match = similar_docs[0]\n",
    "            return {\n",
    "                'doc_id': doc_id,\n",
    "                'is_duplicate': True,\n",
    "                'duplicate_type': 'near',\n",
    "                'similarity': best_match[1],\n",
    "                'similar_to': best_match[0],\n",
    "                'action': 'remove'\n",
    "            }\n",
    "        \n",
    "        # Document is unique\n",
    "        self.deduplication_stats['unique_documents'] += 1\n",
    "        self.processed_documents[doc_id] = {\n",
    "            'text': text,\n",
    "            'signature': signature,\n",
    "            'exact_hash': exact_hash\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'doc_id': doc_id,\n",
    "            'is_duplicate': False,\n",
    "            'duplicate_type': 'none',\n",
    "            'similarity': 0.0,\n",
    "            'action': 'keep'\n",
    "        }\n",
    "    \n",
    "    def get_deduplication_report(self):\n",
    "        \"\"\"Generate deduplication report\"\"\"\n",
    "        stats = self.deduplication_stats.copy()\n",
    "        \n",
    "        if stats['total_documents'] > 0:\n",
    "            stats['exact_duplicate_rate'] = stats['exact_duplicates'] / stats['total_documents']\n",
    "            stats['near_duplicate_rate'] = stats['near_duplicates'] / stats['total_documents']\n",
    "            stats['unique_rate'] = stats['unique_documents'] / stats['total_documents']\n",
    "            stats['total_duplicate_rate'] = (stats['exact_duplicates'] + stats['near_duplicates']) / stats['total_documents']\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Initialize deduplication pipeline\n",
    "dedup_pipeline = DataDeduplicationPipeline()\n",
    "print(\"Data deduplication pipeline initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data Deduplication\n",
    "\n",
    "Let's test our deduplication system with sample documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test documents with various levels of similarity\n",
    "def generate_test_documents():\n",
    "    \"\"\"Generate test documents with exact and near duplicates\"\"\"\n",
    "    base_texts = [\n",
    "        \"Machine learning is a subset of artificial intelligence that enables computers to learn from data without explicit programming.\",\n",
    "        \"Deep learning uses neural networks with multiple layers to model and understand complex patterns in data.\",\n",
    "        \"Natural language processing combines computational linguistics with machine learning to help computers understand human language.\",\n",
    "        \"Computer vision is a field of AI that trains computers to interpret and understand visual information from the world.\",\n",
    "        \"Reinforcement learning is a type of machine learning where agents learn to make decisions through trial and error.\"\n",
    "    ]\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    # Add original documents\n",
    "    for i, text in enumerate(base_texts):\n",
    "        documents.append((f\"doc_{i+1}\", text))\n",
    "    \n",
    "    # Add exact duplicates\n",
    "    documents.append((\"doc_6_exact_dup\", base_texts[0]))  # Exact duplicate of doc_1\n",
    "    documents.append((\"doc_7_exact_dup\", base_texts[1]))  # Exact duplicate of doc_2\n",
    "    \n",
    "    # Add near duplicates (with minor modifications)\n",
    "    near_dup_1 = base_texts[0].replace(\"Machine learning\", \"ML\").replace(\"artificial intelligence\", \"AI\")\n",
    "    documents.append((\"doc_8_near_dup\", near_dup_1))\n",
    "    \n",
    "    near_dup_2 = base_texts[2] + \" This technology is widely used in various applications.\"\n",
    "    documents.append((\"doc_9_near_dup\", near_dup_2))\n",
    "    \n",
    "    # Add some variations\n",
    "    variation_1 = \"Deep neural networks with many layers are used in deep learning to model complex data patterns.\"\n",
    "    documents.append((\"doc_10_variation\", variation_1))\n",
    "    \n",
    "    # Add completely different document\n",
    "    different_doc = \"The weather today is sunny with a temperature of 25 degrees Celsius. Perfect for outdoor activities.\"\n",
    "    documents.append((\"doc_11_different\", different_doc))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Generate test documents\n",
    "test_documents = generate_test_documents()\n",
    "\n",
    "print(f\"Generated {len(test_documents)} test documents\")\n",
    "print(\"\\nProcessing documents through deduplication pipeline...\\n\")\n",
    "\n",
    "# Process documents\n",
    "results = []\n",
    "for doc_id, text in test_documents:\n",
    "    result = dedup_pipeline.process_document(doc_id, text, similarity_threshold=0.7)\n",
    "    results.append(result)\n",
    "    \n",
    "    # Print result\n",
    "    status = \"DUPLICATE\" if result['is_duplicate'] else \"UNIQUE\"\n",
    "    print(f\"{doc_id}: {status}\")\n",
    "    print(f\"  Type: {result['duplicate_type']}\")\n",
    "    print(f\"  Similarity: {result['similarity']:.3f}\")\n",
    "    print(f\"  Action: {result['action']}\")\n",
    "    \n",
    "    if 'similar_to' in result:\n",
    "        print(f\"  Similar to: {result['similar_to']}\")\n",
    "    if 'note' in result:\n",
    "        print(f\"  Note: {result['note']}\")\n",
    "    print()\n",
    "\n",
    "# Generate report\n",
    "report = dedup_pipeline.get_deduplication_report()\n",
    "\n",
    "print(\"=== DEDUPLICATION REPORT ===\")\n",
    "print(f\"Total documents processed: {report['total_documents']}\")\n",
    "print(f\"Exact duplicates found: {report['exact_duplicates']} ({report.get('exact_duplicate_rate', 0):.1%})\")\n",
    "print(f\"Near duplicates found: {report['near_duplicates']} ({report.get('near_duplicate_rate', 0):.1%})\")\n",
    "print(f\"Unique documents: {report['unique_documents']} ({report.get('unique_rate', 0):.1%})\")\n",
    "print(f\"Total duplicate rate: {report.get('total_duplicate_rate', 0):.1%}\")\n",
    "\n",
    "# Visualize results\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Duplicate type distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "duplicate_counts = df_results['duplicate_type'].value_counts()\n",
    "colors = ['lightgreen', 'orange', 'red']\n",
    "plt.pie(duplicate_counts.values, labels=duplicate_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "plt.title('Duplicate Type Distribution')\n",
    "\n",
    "# Similarity distribution\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.hist(df_results['similarity'], bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Similarity Score Distribution')\n",
    "\n",
    "# Action distribution\n",
    "plt.subplot(2, 3, 3)\n",
    "action_counts = df_results['action'].value_counts()\n",
    "plt.bar(action_counts.index, action_counts.values, color=['green', 'red'])\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Action Distribution')\n",
    "\n",
    "# Deduplication effectiveness\n",
    "plt.subplot(2, 3, 4)\n",
    "categories = ['Total', 'Exact Dup', 'Near Dup', 'Unique']\n",
    "values = [report['total_documents'], report['exact_duplicates'], \n",
    "          report['near_duplicates'], report['unique_documents']]\n",
    "colors = ['blue', 'red', 'orange', 'green']\n",
    "plt.bar(categories, values, color=colors)\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Deduplication Results')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Similarity vs Document ID\n",
    "plt.subplot(2, 3, 5)\n",
    "doc_indices = range(len(df_results))\n",
    "colors_map = {'none': 'green', 'exact': 'red', 'near': 'orange'}\n",
    "colors = [colors_map[dtype] for dtype in df_results['duplicate_type']]\n",
    "plt.scatter(doc_indices, df_results['similarity'], c=colors, alpha=0.7, s=60)\n",
    "plt.xlabel('Document Index')\n",
    "plt.ylabel('Similarity Score')\n",
    "plt.title('Similarity Scores by Document')\n",
    "plt.legend(['Unique', 'Exact Duplicate', 'Near Duplicate'])\n",
    "\n",
    "# Data reduction effectiveness\n",
    "plt.subplot(2, 3, 6)\n",
    "original_size = report['total_documents']\n",
    "final_size = report['unique_documents']\n",
    "reduction = original_size - final_size\n",
    "\n",
    "plt.bar(['Original', 'After Dedup'], [original_size, final_size], \n",
    "        color=['lightblue', 'darkblue'])\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.title(f'Data Reduction: {reduction} docs removed ({reduction/original_size:.1%})')\n",
    "\n",
    "# Add reduction annotation\n",
    "plt.annotate(f'-{reduction}\\n({reduction/original_size:.1%})', \n",
    "             xy=(0.5, (original_size + final_size)/2), \n",
    "             ha='center', va='center', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== EFFICIENCY ANALYSIS ===\")\n",
    "print(f\"Data reduction: {reduction} documents ({reduction/original_size:.1%})\")\n",
    "print(f\"Storage savings: ~{reduction/original_size:.1%} (assuming uniform document sizes)\")\n",
    "print(f\"Deduplication precision: {len([r for r in results if r['is_duplicate'] and ('dup' in r['doc_id'] or 'variation' in r['doc_id'])])} / {len([r for r in results if r['is_duplicate']])} detected duplicates were actual duplicates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Filtering System\n",
    "\n",
    "Let's implement a comprehensive data quality filtering system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataQualityFilter:\n",
    "    \"\"\"Comprehensive data quality filtering system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.quality_metrics = {\n",
    "            'length': self.check_length_quality,\n",
    "            'language': self.check_language_quality,\n",
    "            'content': self.check_content_quality,\n",
    "            'structure': self.check_structure_quality,\n",
    "            'encoding': self.check_encoding_quality\n",
    "        }\n",
    "        \n",
    "        self.filter_stats = defaultdict(int)\n",
    "        \n",
    "        # Quality thresholds\n",
    "        self.thresholds = {\n",
    "            'min_length': 50,\n",
    "            'max_length': 10000,\n",
    "            'min_words': 10,\n",
    "            'max_repetition_ratio': 0.3,\n",
    "            'min_alpha_ratio': 0.6,\n",
    "            'max_special_char_ratio': 0.1,\n",
    "            'min_sentence_count': 2,\n",
    "            'max_avg_word_length': 15\n",
    "        }\n",
    "    \n",
    "    def assess_document_quality(self, text, doc_id=None):\n",
    "        \"\"\"Assess overall document quality\"\"\"\n",
    "        quality_assessment = {\n",
    "            'doc_id': doc_id,\n",
    "            'overall_score': 0.0,\n",
    "            'individual_scores': {},\n",
    "            'passed_filters': [],\n",
    "            'failed_filters': [],\n",
    "            'quality_issues': [],\n",
    "            'recommendation': 'unknown'\n",
    "        }\n",
    "        \n",
    "        total_score = 0\n",
    "        \n",
    "        # Run all quality checks\n",
    "        for metric_name, metric_func in self.quality_metrics.items():\n",
    "            try:\n",
    "                score, passed, issues = metric_func(text)\n",
    "                quality_assessment['individual_scores'][metric_name] = score\n",
    "                total_score += score\n",
    "                \n",
    "                if passed:\n",
    "                    quality_assessment['passed_filters'].append(metric_name)\n",
    "                else:\n",
    "                    quality_assessment['failed_filters'].append(metric_name)\n",
    "                    quality_assessment['quality_issues'].extend(issues)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                quality_assessment['individual_scores'][metric_name] = 0.0\n",
    "                quality_assessment['failed_filters'].append(metric_name)\n",
    "                quality_assessment['quality_issues'].append(f\"{metric_name}_error: {str(e)}\")\n",
    "        \n",
    "        # Calculate overall score\n",
    "        quality_assessment['overall_score'] = total_score / len(self.quality_metrics)\n",
    "        \n",
    "        # Make recommendation\n",
    "        quality_assessment['recommendation'] = self.make_quality_recommendation(\n",
    "            quality_assessment['overall_score'], \n",
    "            quality_assessment['failed_filters']\n",
    "        )\n",
    "        \n",
    "        # Update statistics\n",
    "        self.filter_stats['total_documents'] += 1\n",
    "        if quality_assessment['recommendation'] == 'accept':\n",
    "            self.filter_stats['accepted_documents'] += 1\n",
    "        elif quality_assessment['recommendation'] == 'reject':\n",
    "            self.filter_stats['rejected_documents'] += 1\n",
    "        else:\n",
    "            self.filter_stats['review_documents'] += 1\n",
    "        \n",
    "        return quality_assessment\n",
    "    \n",
    "    def check_length_quality(self, text):\n",
    "        \"\"\"Check document length quality\"\"\"\n",
    "        char_count = len(text)\n",
    "        word_count = len(text.split())\n",
    "        \n",
    "        issues = []\n",
    "        score = 1.0\n",
    "        \n",
    "        # Check character length\n",
    "        if char_count < self.thresholds['min_length']:\n",
    "            issues.append(f\"Too short: {char_count} chars < {self.thresholds['min_length']}\")\n",
    "            score *= 0.3\n",
    "        elif char_count > self.thresholds['max_length']:\n",
    "            issues.append(f\"Too long: {char_count} chars > {self.thresholds['max_length']}\")\n",
    "            score *= 0.7\n",
    "        \n",
    "        # Check word count\n",
    "        if word_count < self.thresholds['min_words']:\n",
    "            issues.append(f\"Too few words: {word_count} < {self.thresholds['min_words']}\")\n",
    "            score *= 0.5\n",
    "        \n",
    "        passed = len(issues) == 0\n",
    "        return score, passed, issues\n",
    "    \n",
    "    def check_language_quality(self, text):\n",
    "        \"\"\"Check language and character quality\"\"\"\n",
    "        issues = []\n",
    "        score = 1.0\n",
    "        \n",
    "        # Calculate character ratios\n",
    "        total_chars = len(text)\n",
    "        if total_chars == 0:\n",
    "            return 0.0, False, ['Empty text']\n",
    "        \n",
    "        alpha_chars = sum(1 for c in text if c.isalpha())\n",
    "        digit_chars = sum(1 for c in text if c.isdigit())\n",
    "        space_chars = sum(1 for c in text if c.isspace())\n",
    "        special_chars = total_chars - alpha_chars - digit_chars - space_chars\n",
    "        \n",
    "        alpha_ratio = alpha_chars / total_chars\n",
    "        special_ratio = special_chars / total_chars\n",
    "        \n",
    "        # Check alphabetic character ratio\n",
    "        if alpha_ratio < self.thresholds['min_alpha_ratio']:\n",
    "            issues.append(f\"Low alphabetic ratio: {alpha_ratio:.2f} < {self.thresholds['min_alpha_ratio']}\")\n",
    "            score *= 0.6\n",
    "        \n",
    "        # Check special character ratio\n",
    "        if special_ratio > self.thresholds['max_special_char_ratio']:\n",
    "            issues.append(f\"High special char ratio: {special_ratio:.2f} > {self.thresholds['max_special_char_ratio']}\")\n",
    "            score *= 0.7\n",
    "        \n",
    "        # Check for non-printable characters\n",
    "        non_printable = sum(1 for c in text if ord(c) < 32 and c not in '\\t\\n\\r')\n",
    "        if non_printable > 0:\n",
    "            issues.append(f\"Contains {non_printable} non-printable characters\")\n",
    "            score *= 0.8\n",
    "        \n",
    "        passed = len(issues) == 0\n",
    "        return score, passed, issues\n",
    "    \n",
    "    def check_content_quality(self, text):\n",
    "        \"\"\"Check content quality and repetition\"\"\"\n",
    "        issues = []\n",
    "        score = 1.0\n",
    "        \n",
    "        words = text.lower().split()\n",
    "        if not words:\n",
    "            return 0.0, False, ['No words found']\n",
    "        \n",
    "        # Check repetition\n",
    "        word_counts = Counter(words)\n",
    "        most_common_word, max_count = word_counts.most_common(1)[0]\n",
    "        repetition_ratio = max_count / len(words)\n",
    "        \n",
    "        if repetition_ratio > self.thresholds['max_repetition_ratio']:\n",
    "            issues.append(f\"High repetition: '{most_common_word}' appears {repetition_ratio:.2f} of the time\")\n",
    "            score *= 0.5\n",
    "        \n",
    "        # Check average word length\n",
    "        avg_word_length = sum(len(word) for word in words) / len(words)\n",
    "        if avg_word_length > self.thresholds['max_avg_word_length']:\n",
    "            issues.append(f\"Unusually long words: avg {avg_word_length:.1f} chars\")\n",
    "            score *= 0.8\n",
    "        \n",
    "        # Check for excessive capitalization\n",
    "        caps_ratio = sum(1 for c in text if c.isupper()) / len(text)\n",
    "        if caps_ratio > 0.3:\n",
    "            issues.append(f\"Excessive capitalization: {caps_ratio:.2f}\")\n",
    "            score *= 0.7\n",
    "        \n",
    "        passed = len(issues) == 0\n",
    "        return score, passed, issues\n",
    "    \n",
    "    def check_structure_quality(self, text):\n",
    "        \"\"\"Check document structure quality\"\"\"\n",
    "        issues = []\n",
    "        score = 1.0\n",
    "        \n",
    "        # Check sentence structure\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        sentence_count = len(sentences)\n",
    "        \n",
    "        if sentence_count < self.thresholds['min_sentence_count']:\n",
    "            issues.append(f\"Too few sentences: {sentence_count} < {self.thresholds['min_sentence_count']}\")\n",
    "            score *= 0.6\n",
    "        \n",
    "        # Check sentence length variation\n",
    "        if sentences:\n",
    "            sentence_lengths = [len(sent.split()) for sent in sentences]\n",
    "            avg_sent_length = np.mean(sentence_lengths)\n",
    "            \n",
    "            if avg_sent_length < 3:\n",
    "                issues.append(f\"Very short sentences: avg {avg_sent_length:.1f} words\")\n",
    "                score *= 0.7\n",
    "            elif avg_sent_length > 50:\n",
    "                issues.append(f\"Very long sentences: avg {avg_sent_length:.1f} words\")\n",
    "                score *= 0.8\n",
    "        \n",
    "        # Check paragraph structure (simple heuristic)\n",
    "        paragraphs = text.split('\\n\\n')\n",
    "        if len(paragraphs) == 1 and len(text) > 1000:\n",
    "            issues.append(\"Long text without paragraph breaks\")\n",
    "            score *= 0.9\n",
    "        \n",
    "        passed = len(issues) == 0\n",
    "        return score, passed, issues\n",
    "    \n",
    "    def check_encoding_quality(self, text):\n",
    "        \"\"\"Check text encoding quality\"\"\"\n",
    "        issues = []\n",
    "        score = 1.0\n",
    "        \n",
    "        # Check for encoding artifacts\n",
    "        encoding_artifacts = ['�', '\\ufffd', '\\x00']\n",
    "        for artifact in encoding_artifacts:\n",
    "            if artifact in text:\n",
    "                issues.append(f\"Contains encoding artifact: {repr(artifact)}\")\n",
    "                score *= 0.5\n",
    "        \n",
    "        # Check for excessive whitespace\n",
    "        whitespace_ratio = sum(1 for c in text if c.isspace()) / len(text) if text else 0\n",
    "        if whitespace_ratio > 0.4:\n",
    "            issues.append(f\"Excessive whitespace: {whitespace_ratio:.2f}\")\n",
    "            score *= 0.8\n",
    "        \n",
    "        # Check for repeated whitespace patterns\n",
    "        if re.search(r'\\s{10,}', text):\n",
    "            issues.append(\"Contains long sequences of whitespace\")\n",
    "            score *= 0.9\n",
    "        \n",
    "        passed = len(issues) == 0\n",
    "        return score, passed, issues\n",
    "    \n",
    "    def make_quality_recommendation(self, overall_score, failed_filters):\n",
    "        \"\"\"Make recommendation based on quality assessment\"\"\"\n",
    "        critical_filters = ['length', 'encoding']\n",
    "        \n",
    "        # Reject if critical filters failed\n",
    "        if any(f in failed_filters for f in critical_filters):\n",
    "            return 'reject'\n",
    "        \n",
    "        # Accept if high quality\n",
    "        if overall_score >= 0.8:\n",
    "            return 'accept'\n",
    "        \n",
    "        # Reject if very low quality\n",
    "        elif overall_score < 0.4:\n",
    "            return 'reject'\n",
    "        \n",
    "        # Review for medium quality\n",
    "        else:\n",
    "            return 'review'\n",
    "    \n",
    "    def get_filter_statistics(self):\n",
    "        \"\"\"Get filtering statistics\"\"\"\n",
    "        stats = dict(self.filter_stats)\n",
    "        \n",
    "        if stats.get('total_documents', 0) > 0:\n",
    "            total = stats['total_documents']\n",
    "            stats['acceptance_rate'] = stats.get('accepted_documents', 0) / total\n",
    "            stats['rejection_rate'] = stats.get('rejected_documents', 0) / total\n",
    "            stats['review_rate'] = stats.get('review_documents', 0) / total\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Initialize quality filter\n",
    "quality_filter = DataQualityFilter()\n",
    "print(\"Data quality filter initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data Quality Filtering\n",
    "\n",
    "Let's test our quality filtering system with various document types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test documents with various quality levels\n",
    "def generate_quality_test_documents():\n",
    "    \"\"\"Generate documents with different quality characteristics\"\"\"\n",
    "    documents = [\n",
    "        # High quality document\n",
    "        (\"high_quality\", \n",
    "         \"Machine learning has revolutionized many industries by enabling computers to learn from data. \"\n",
    "         \"This technology uses algorithms to identify patterns and make predictions without explicit programming. \"\n",
    "         \"Applications range from image recognition to natural language processing, transforming how we interact with technology.\"),\n",
    "        \n",
    "        # Too short document\n",
    "        (\"too_short\", \"ML is good.\"),\n",
    "        \n",
    "        # Repetitive document\n",
    "        (\"repetitive\", \n",
    "         \"The the the the the machine machine machine learning learning learning is is is very very very good good good. \"\n",
    "         \"Machine machine machine learning learning learning helps helps helps us us us solve solve solve problems problems problems.\"),\n",
    "        \n",
    "        # High special character ratio\n",
    "        (\"special_chars\", \n",
    "         \"M@ch!n3 l3@rn!ng !$ @ $ub$3t 0f @rt!f!c!@l !nt3ll!g3nc3 th@t 3n@bl3$ c0mput3r$ t0 l3@rn fr0m d@t@. \"\n",
    "         \"Th!$ t3chn0l0gy u$3$ @lg0r!thm$ t0 !d3nt!fy p@tt3rn$ @nd m@k3 pr3d!ct!0n$.\"),\n",
    "        \n",
    "        # Excessive capitalization\n",
    "        (\"excessive_caps\", \n",
    "         \"MACHINE LEARNING IS A SUBSET OF ARTIFICIAL INTELLIGENCE THAT ENABLES COMPUTERS TO LEARN FROM DATA. \"\n",
    "         \"THIS TECHNOLOGY USES ALGORITHMS TO IDENTIFY PATTERNS AND MAKE PREDICTIONS WITHOUT EXPLICIT PROGRAMMING.\"),\n",
    "        \n",
    "        # Very long sentences\n",
    "        (\"long_sentences\", \n",
    "         \"Machine learning which is a subset of artificial intelligence that enables computers to learn from data \"\n",
    "         \"without explicit programming and uses algorithms to identify patterns and make predictions has revolutionized \"\n",
    "         \"many industries including healthcare finance transportation and technology by providing automated solutions \"\n",
    "         \"that can process vast amounts of information and extract meaningful insights that would be impossible for \"\n",
    "         \"humans to analyze manually in a reasonable timeframe.\"),\n",
    "        \n",
    "        # Encoding issues (simulated)\n",
    "        (\"encoding_issues\", \n",
    "         \"Machine learning is a subset of artificial intelligence� that enables computers to learn from data. \"\n",
    "         \"This technology uses algorithms\\x00 to identify patterns and make predictions.\"),\n",
    "        \n",
    "        # Medium quality document\n",
    "        (\"medium_quality\", \n",
    "         \"AI and machine learning are important. They help solve problems. Many companies use these technologies. \"\n",
    "         \"The future looks promising for AI development and implementation in various sectors.\"),\n",
    "        \n",
    "        # Empty document\n",
    "        (\"empty\", \"\"),\n",
    "        \n",
    "        # Excessive whitespace\n",
    "        (\"whitespace_issues\", \n",
    "         \"Machine    learning         is    a    subset         of    artificial         intelligence.    \"\n",
    "         \"This         technology         uses         algorithms         to         identify         patterns.\")\n",
    "    ]\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Generate and process test documents\n",
    "quality_test_docs = generate_quality_test_documents()\n",
    "\n",
    "print(f\"Testing {len(quality_test_docs)} documents for quality...\\n\")\n",
    "\n",
    "quality_results = []\n",
    "for doc_id, text in quality_test_docs:\n",
    "    assessment = quality_filter.assess_document_quality(text, doc_id)\n",
    "    quality_results.append(assessment)\n",
    "    \n",
    "    print(f\"Document: {doc_id}\")\n",
    "    print(f\"  Overall Score: {assessment['overall_score']:.3f}\")\n",
    "    print(f\"  Recommendation: {assessment['recommendation'].upper()}\")\n",
    "    print(f\"  Passed Filters: {', '.join(assessment['passed_filters']) if assessment['passed_filters'] else 'None'}\")\n",
    "    print(f\"  Failed Filters: {', '.join(assessment['failed_filters']) if assessment['failed_filters'] else 'None'}\")\n",
    "    \n",
    "    if assessment['quality_issues']:\n",
    "        print(f\"  Issues:\")\n",
    "        for issue in assessment['quality_issues'][:3]:  # Show first 3 issues\n",
    "            print(f\"    - {issue}\")\n",
    "    \n",
    "    print(f\"  Individual Scores:\")\n",
    "    for metric, score in assessment['individual_scores'].items():\n",
    "        print(f\"    {metric}: {score:.3f}\")\n",
    "    print()\n",
    "\n",
    "# Get filtering statistics\n",
    "filter_stats = quality_filter.get_filter_statistics()\n",
    "\n",
    "print(\"=== QUALITY FILTERING STATISTICS ===\")\n",
    "print(f\"Total documents: {filter_stats['total_documents']}\")\n",
    "print(f\"Accepted: {filter_stats.get('accepted_documents', 0)} ({filter_stats.get('acceptance_rate', 0):.1%})\")\n",
    "print(f\"Rejected: {filter_stats.get('rejected_documents', 0)} ({filter_stats.get('rejection_rate', 0):.1%})\")\n",
    "print(f\"Need Review: {filter_stats.get('review_documents', 0)} ({filter_stats.get('review_rate', 0):.1%})\")\n",
    "\n",
    "# Visualize quality assessment results\n",
    "df_quality = pd.DataFrame(quality_results)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Overall quality scores\n",
    "plt.subplot(3, 3, 1)\n",
    "doc_names = [result['doc_id'] for result in quality_results]\n",
    "scores = [result['overall_score'] for result in quality_results]\n",
    "colors = ['green' if score >= 0.8 else 'orange' if score >= 0.4 else 'red' for score in scores]\n",
    "plt.bar(range(len(scores)), scores, color=colors)\n",
    "plt.xlabel('Document')\n",
    "plt.ylabel('Quality Score')\n",
    "plt.title('Overall Quality Scores')\n",
    "plt.xticks(range(len(doc_names)), doc_names, rotation=45, ha='right')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Recommendation distribution\n",
    "plt.subplot(3, 3, 2)\n",
    "recommendations = [result['recommendation'] for result in quality_results]\n",
    "rec_counts = Counter(recommendations)\n",
    "colors = ['green', 'orange', 'red']\n",
    "plt.pie(rec_counts.values(), labels=rec_counts.keys(), autopct='%1.1f%%', colors=colors)\n",
    "plt.title('Recommendation Distribution')\n",
    "\n",
    "# Individual metric scores heatmap\n",
    "plt.subplot(3, 3, 3)\n",
    "metrics = ['length', 'language', 'content', 'structure', 'encoding']\n",
    "score_matrix = []\n",
    "for result in quality_results:\n",
    "    row = [result['individual_scores'].get(metric, 0) for metric in metrics]\n",
    "    score_matrix.append(row)\n",
    "\n",
    "score_matrix = np.array(score_matrix)\n",
    "im = plt.imshow(score_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "plt.colorbar(im)\n",
    "plt.xlabel('Quality Metrics')\n",
    "plt.ylabel('Documents')\n",
    "plt.title('Individual Metric Scores')\n",
    "plt.xticks(range(len(metrics)), metrics, rotation=45)\n",
    "plt.yticks(range(len(doc_names)), doc_names)\n",
    "\n",
    "# Failed filters analysis\n",
    "plt.subplot(3, 3, 4)\n",
    "all_failed_filters = []\n",
    "for result in quality_results:\n",
    "    all_failed_filters.extend(result['failed_filters'])\n",
    "failed_counts = Counter(all_failed_filters)\n",
    "if failed_counts:\n",
    "    plt.bar(failed_counts.keys(), failed_counts.values(), color='red', alpha=0.7)\n",
    "    plt.xlabel('Filter Type')\n",
    "    plt.ylabel('Failure Count')\n",
    "    plt.title('Most Common Filter Failures')\n",
    "    plt.xticks(rotation=45)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'No Filter Failures', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.title('Filter Failures')\n",
    "\n",
    "# Quality score distribution\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.hist(scores, bins=10, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(x=0.8, color='green', linestyle='--', label='Accept Threshold')\n",
    "plt.axvline(x=0.4, color='red', linestyle='--', label='Reject Threshold')\n",
    "plt.xlabel('Quality Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Quality Score Distribution')\n",
    "plt.legend()\n",
    "\n",
    "# Quality vs Document Length\n",
    "plt.subplot(3, 3, 6)\n",
    "doc_lengths = [len(doc[1]) for doc in quality_test_docs]\n",
    "plt.scatter(doc_lengths, scores, c=colors, alpha=0.7, s=60)\n",
    "plt.xlabel('Document Length (characters)')\n",
    "plt.ylabel('Quality Score')\n",
    "plt.title('Quality vs Document Length')\n",
    "\n",
    "# Filter pass rate by metric\n",
    "plt.subplot(3, 3, 7)\n",
    "pass_rates = {}\n",
    "for metric in metrics:\n",
    "    passed = sum(1 for result in quality_results if metric in result['passed_filters'])\n",
    "    pass_rates[metric] = passed / len(quality_results)\n",
    "\n",
    "plt.bar(pass_rates.keys(), pass_rates.values(), color='lightblue')\n",
    "plt.xlabel('Quality Metric')\n",
    "plt.ylabel('Pass Rate')\n",
    "plt.title('Filter Pass Rates')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Quality improvement potential\n",
    "plt.subplot(3, 3, 8)\n",
    "improvement_potential = [1 - score for score in scores]\n",
    "plt.bar(range(len(improvement_potential)), improvement_potential, color='orange', alpha=0.7)\n",
    "plt.xlabel('Document')\n",
    "plt.ylabel('Improvement Potential')\n",
    "plt.title('Quality Improvement Potential')\n",
    "plt.xticks(range(len(doc_names)), doc_names, rotation=45, ha='right')\n",
    "\n",
    "# Data retention after filtering\n",
    "plt.subplot(3, 3, 9)\n",
    "accepted = sum(1 for r in recommendations if r == 'accept')\n",
    "rejected = sum(1 for r in recommendations if r == 'reject')\n",
    "review = sum(1 for r in recommendations if r == 'review')\n",
    "\n",
    "categories = ['Original', 'After Filtering']\n",
    "original_count = len(quality_results)\n",
    "retained_count = accepted + review  # Assuming review items might be kept\n",
    "\n",
    "plt.bar(categories, [original_count, retained_count], color=['lightblue', 'darkblue'])\n",
    "plt.ylabel('Number of Documents')\n",
    "plt.title(f'Data Retention: {retained_count}/{original_count} ({retained_count/original_count:.1%})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== QUALITY ANALYSIS SUMMARY ===\")\n",
    "print(f\"Average quality score: {np.mean(scores):.3f}\")\n",
    "print(f\"Quality score std dev: {np.std(scores):.3f}\")\n",
    "print(f\"Highest quality: {max(scores):.3f} ({doc_names[scores.index(max(scores))]})\")\n",
    "print(f\"Lowest quality: {min(scores):.3f} ({doc_names[scores.index(min(scores))]})\")\n",
    "print(f\"Data retention rate: {retained_count/original_count:.1%}\")\n",
    "print(f\"Most common quality issues: {dict(Counter(all_failed_filters).most_common(3))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}